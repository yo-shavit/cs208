{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4a Submission\n",
    "## Yonadav Shavit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.special import factorial\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Let's define some latex commands)\n",
    " \n",
    "$\\newcommand{\\floor}[1]{\\left \\lfloor #1 \\right \\rfloor}$\n",
    "$\\newcommand{\\clamp}[1]{\\left [ #1 \\right ]}$\n",
    "$\\newcommand{\\lap}[1]{Lap\\left ( #1 \\right )}$\n",
    "$\\newcommand{\\lapcdf}[2]{LapCDF\\left ( #1, [-\\inf, #2] \\right )}$\n",
    "$\\newcommand{\\lappdf}[2]{LapPDF\\left ( #1, |_{#2} \\right )}$\n",
    "$\\newcommand{\\lapcdffull}[2]{\\frac{1}{2} + \\frac{1}{2}sgn\\left({#2}\\right)\\left ( 1 - \\exp{\\left ( - \\frac{|#2|}{#1} \\right ) }\\right )}$\n",
    "$\\newcommand{\\lappdffull}[2]{\\frac{1}{2 #1} \\exp{\\left ( - \\frac{#2}{#1}\\right ) }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be implementing two different mechanisms, both of which rely on an estimation of $p_j$.\n",
    "\n",
    "In the local DP case, we'll compute $I(x[j] = 0 \\land y = 1)$, and then return that value (or its conjugate) with probability $\\frac{e^\\epsilon}{1 + e^\\epsilon}$, and then scale that up by a factor of $c_\\epsilon = \\frac{e^\\epsilon + 1}{e^\\epsilon - 1}$.\n",
    "\n",
    "In the centralized DP case, we'll compute $\\frac{1}{n}\\sum_{i = 0}^n{I(x_i[j] = 0 \\land y_i = 1)}$, and then add Laplace noise of magnitude $\\frac{1}{n\\epsilon}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/hw4testdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_toy = df[[col for col in df.columns if \"x\" in col]].values\n",
    "Y_toy = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_pj(Xj, Y, epsilon):\n",
    "    n = Xj.shape[0]\n",
    "    eeps = np.exp(epsilon)\n",
    "    correct_vals = (1-Xj)*Y\n",
    "    flip_bit = np.random.binomial(1, 1/(1+eeps), size=n).astype(bool)\n",
    "    randomized_vals = np.logical_xor(flip_bit, correct_vals)\n",
    "    c_e = (eeps + 1)/(eeps - 1)\n",
    "    return c_e*randomized_vals.mean()\n",
    "\n",
    "def lap_mechanism(epsilon, GS_q, size=None):\n",
    "    return np.random.laplace(scale=GS_q/epsilon, size=size)\n",
    "\n",
    "def dp_mean(x, epsilon, b, a=0):\n",
    "    x_clipped = np.clip(x, a, b)\n",
    "    GS_q = np.abs(b-a)/x.shape[0]\n",
    "    return x_clipped.mean() + lap_mechanism(epsilon, GS_q)\n",
    "\n",
    "def centralized_pj(Xj, Y, epsilon):\n",
    "    return dp_mean(((1-Xj)*Y).astype(int), epsilon, b=1)\n",
    "\n",
    "def sq_mechanism(X, Y, epsilon, t, pj_alg):\n",
    "    d = X.shape[1]\n",
    "    ps = np.array([pj_alg(X[:, j], Y, epsilon/d) for j in range(d)])\n",
    "    S = (ps < t).astype(int)\n",
    "    return S\n",
    "\n",
    "local_sq_mechanism = lambda *args: sq_mechanism(*args, local_pj)\n",
    "centralized_sq_mechanism = lambda *args: sq_mechanism(*args, centralized_pj)\n",
    "\n",
    "def compute_statistics(S, X, Y):\n",
    "    \"\"\" Error, FPR, and FNR\n",
    "    \"\"\"\n",
    "    Yhat = ((S*X_test).sum(axis=1) == S.sum()).astype(int)\n",
    "    fpr = (Yhat*(1-Y)).mean()\n",
    "    fnr = ((1-Yhat)*Y).mean()\n",
    "    error_rate = fpr + fnr\n",
    "    return error_rate, fpr, fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will leverage the following approximation to the binomial distribution, which holds under large $n$:\n",
    "$$f(x)=\n",
    "\\frac{n !}{x !(n-x) !} p^{x} q^{n-x} \\approx \n",
    "\\mathcal{N}(np, np(1-p)) = \n",
    "\\frac{1}{\\sqrt{2 \\pi n p (1-p)}} e^{-\\frac{(x-n p)^{2}}{2 n p (1-p)}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll think about the global model.\n",
    "\n",
    "Let's examine the probability that $j$ is included in $\\hat{S}$ but not $S$ (i.e. false inclusion). \n",
    "Let $\\epsilon_j$ be the privacy loss parameter associated with computing $p_j$ (in practice $\\frac{\\epsilon}{d}$).\n",
    "Remember that $p_j = 0$ for $j \\in S$.\n",
    "\n",
    "$$P(j \\notin \\hat{S} \\land j \\in S) = \n",
    "P\\left(0 + \\lap{\\frac{1}{n\\epsilon_j}} > t\\right) = \n",
    "1 - \\left(\\lapcdffull{\\frac{1}{n\\epsilon_j}}{t} \\right)= \n",
    "\\frac{1}{2}\\exp{\\left ( -tn\\epsilon_j \\right )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that any of the $j$'s in $S$ is excluded from $\\hat{S}$ is simply:\n",
    "$$ P(S \\not\\subseteq \\hat{S}) = \n",
    "1 - \\prod_{j \\in S} \\left ( 1 - P(j \\notin \\hat{S} \\land j \\in S)\\right ) = \n",
    "1 - \\left(1 - \\frac{1}{2}\\exp{\\left ( -tn\\epsilon_j \\right )} \\right )^{|S|} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to ensure the false exclusion rate is below $0.1$, we need:\n",
    "$$ t >  \\frac{-d}{n\\epsilon}\\log{\\left(2 - 2\\sqrt[d]{0.9} \\right )} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's think about the local model.\n",
    "\n",
    "Note that because each response (out of $n$) used to calculate a particular $p_j$ is a single Bernoulli RV, we can treat their overall average as the response of a Bernoulli RV with $p=\\frac{1}{e^{\\epsilon_j} + 1}$ and $n$ trials.\n",
    "The probability that $j$ is included in $\\hat{S}$ but not $S$ is the same as the probability of that Bernoulli distribution reaching a value less than $\\frac{tn}{c_{\\epsilon_j}}$:\n",
    "\n",
    "$$P(j \\notin \\hat{S} \\land j \\in S) =\n",
    "1 - GaussianCDF\\left( \\frac{tn}{c_{\\epsilon_j}}; \\frac{n}{e^{\\epsilon_j} + 1}, \\frac{ne^{\\epsilon_j}}{(1 + e^{\\epsilon_j})^2} \\right) = \n",
    "NormalCDF \\left( -1 \\times (e^{\\epsilon_j} + 1)\\frac{\\frac{tn}{c_{\\epsilon_j}} - \\frac{n}{e^{\\epsilon_j} + 1}}{e^{\\epsilon_j/2}\\sqrt{n}} \\right ) = \n",
    "NormalCDF \\left( \\left (-t\\left(e^{\\epsilon_j} - 1\\right) + 1 \\right ) \\frac{\\sqrt{n}}{e^{\\epsilon_j/2}} \\right )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the combined probability of any exclusion is:\n",
    "$$ P(S \\not\\subseteq \\hat{S}) = \n",
    "1 - \\prod_{j \\in S} \\left ( 1 - P(j \\notin \\hat{S} \\land j \\in S)\\right ) = \n",
    "1- \\left (NormalCDF \\left( \\left (t\\left(e^{\\frac{\\epsilon}{d}} - 1\\right ) - 1 \\right ) \\frac{\\sqrt{n}}{e^{\\frac{\\epsilon}{2d}}} \\right ) \\right )^{|S|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We'll forgo calculating an appropriate $t$ analytically, and just solve the above equation computationally given the used parameters.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>married</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>collegedegree</th>\n",
       "      <th>employed</th>\n",
       "      <th>militaryservice</th>\n",
       "      <th>uscitizen</th>\n",
       "      <th>disability</th>\n",
       "      <th>englishability</th>\n",
       "      <th>blackfemale</th>\n",
       "      <th>targetted</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "      <td>1.223992e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.543500e-01</td>\n",
       "      <td>6.290482e-02</td>\n",
       "      <td>1.232328e-01</td>\n",
       "      <td>3.037610e-01</td>\n",
       "      <td>5.905047e-01</td>\n",
       "      <td>1.313971e-01</td>\n",
       "      <td>8.124939e-01</td>\n",
       "      <td>2.358398e-01</td>\n",
       "      <td>8.785017e-01</td>\n",
       "      <td>3.324450e-02</td>\n",
       "      <td>2.538946e-01</td>\n",
       "      <td>5.120834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.970375e-01</td>\n",
       "      <td>2.427918e-01</td>\n",
       "      <td>3.287044e-01</td>\n",
       "      <td>4.598809e-01</td>\n",
       "      <td>4.917409e-01</td>\n",
       "      <td>3.378343e-01</td>\n",
       "      <td>3.903174e-01</td>\n",
       "      <td>4.245227e-01</td>\n",
       "      <td>3.267057e-01</td>\n",
       "      <td>1.792744e-01</td>\n",
       "      <td>4.352382e-01</td>\n",
       "      <td>4.998542e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            married         black         asian  collegedegree      employed  \\\n",
       "count  1.223992e+06  1.223992e+06  1.223992e+06   1.223992e+06  1.223992e+06   \n",
       "mean   5.543500e-01  6.290482e-02  1.232328e-01   3.037610e-01  5.905047e-01   \n",
       "std    4.970375e-01  2.427918e-01  3.287044e-01   4.598809e-01  4.917409e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "50%    1.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00  1.000000e+00   \n",
       "75%    1.000000e+00  0.000000e+00  0.000000e+00   1.000000e+00  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00   1.000000e+00  1.000000e+00   \n",
       "\n",
       "       militaryservice     uscitizen    disability  englishability  \\\n",
       "count     1.223992e+06  1.223992e+06  1.223992e+06    1.223992e+06   \n",
       "mean      1.313971e-01  8.124939e-01  2.358398e-01    8.785017e-01   \n",
       "std       3.378343e-01  3.903174e-01  4.245227e-01    3.267057e-01   \n",
       "min       0.000000e+00  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "25%       0.000000e+00  1.000000e+00  0.000000e+00    1.000000e+00   \n",
       "50%       0.000000e+00  1.000000e+00  0.000000e+00    1.000000e+00   \n",
       "75%       0.000000e+00  1.000000e+00  0.000000e+00    1.000000e+00   \n",
       "max       1.000000e+00  1.000000e+00  1.000000e+00    1.000000e+00   \n",
       "\n",
       "        blackfemale     targetted        female  \n",
       "count  1.223992e+06  1.223992e+06  1.223992e+06  \n",
       "mean   3.324450e-02  2.538946e-01  5.120834e-01  \n",
       "std    1.792744e-01  4.352382e-01  4.998542e-01  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "75%    0.000000e+00  1.000000e+00  1.000000e+00  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 1210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/CaPUMS5full.csv\")\n",
    "df['female'] = df['sex']\n",
    "df = df.drop(columns=['sex'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = int(0.8*df.shape[0])\n",
    "features = df.drop(columns=['blackfemale', 'targetted'])\n",
    "# create dummy variables for the inverse property\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in ['blackfemale', 'targetted']:\n",
    "        features['not_'+col] = 1 - df[col]\n",
    "X_train, X_test = features.values[:train_test_split, :], features.values[train_test_split:, :]\n",
    "# Y_train, Y_test = df['blackfemale'].values[:train_test_split], df['blackfemale'].values[train_test_split:]\n",
    "Y_train, Y_test = df['targetted'].values[:train_test_split], df['targetted'].values[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1\n",
    "n_train, d_train = X_train.shape\n",
    "\n",
    "def compute_centralized_t(n, d, eps, target_pfi=0.1):\n",
    "    t_centralized = -np.log(2 - 2*(1-target_pfi)**(1/d))*d/(n*eps)\n",
    "    return t_centralized\n",
    "\n",
    "from scipy.stats import norm\n",
    "def compute_local_p_false_exclusion(n, d, eps, t):\n",
    "    eeps = np.exp(eps/d)\n",
    "    arg = (t*(eeps - 1) - 1)*np.sqrt(n/eeps)\n",
    "    p_false_inclusion = 1 - (norm.cdf(arg))**d\n",
    "    return p_false_inclusion\n",
    "    \n",
    "tolerance = 1e-3\n",
    "def compute_local_t(n, d, eps, target_pfe=0.1):\n",
    "    upper = 1000\n",
    "    lower = 1e-9\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == 1000:\n",
    "            print(i, t_guess)\n",
    "            return\n",
    "        t_guess = (upper + lower)/2\n",
    "        pfe = compute_local_p_false_exclusion(n, d, eps, t_guess)\n",
    "        if pfe > target_pfe + tolerance:\n",
    "            lower = t_guess\n",
    "        elif pfe < target_pfe:\n",
    "            upper = t_guess\n",
    "        else:\n",
    "            return t_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralized model t: 9.30477500729864e-05\n",
      "Local model t: 19.555807114627903\n"
     ]
    }
   ],
   "source": [
    "t_central = compute_centralized_t(n_train, d_train, eps)\n",
    "t_local = compute_local_t(n_train, d_train, eps)\n",
    "print(f\"Centralized model t: {t_central}\")\n",
    "print(f\"Local model t: {t_local}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrs predicted by local model: ['employed', 'uscitizen', 'englishability', 'not_black', 'not_asian', 'not_militaryservice', 'not_female']\n",
      "Attrs predicted by centralized model: ['employed', 'uscitizen', 'englishability', 'not_female']\n"
     ]
    }
   ],
   "source": [
    "# First let's look at our ability to predict black female targetting\n",
    "S_local = local_sq_mechanism(X_train, Y_train, eps, t_local)\n",
    "S_centralized = centralized_sq_mechanism(X_train, Y_train, eps, t_central)\n",
    "print(\"Attrs predicted by local model: {}\".format([features.columns[i] for i in range(X_train.shape[1]) if S_local[i]]))\n",
    "print(\"Attrs predicted by centralized model: {}\".format([features.columns[i] for i in range(X_train.shape[1]) if S_centralized[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, employed + uscitizen + englishability + notfemale perfectly predicts the target variable, so both solutions achieved the correct outcome (with the local model having many more false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c21398695104a8e8fc50315852bbdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error rate with the local model was 0.08981572637143127\n",
      "The average error rate with the centralized model was 0.002398947708119723\n"
     ]
    }
   ],
   "source": [
    "trials = 50\n",
    "avg_err_local = 0\n",
    "avg_err_centralized = 0\n",
    "for _ in tqdm_notebook(range(trials)):\n",
    "    S_local = local_sq_mechanism(X_train, Y_train, eps, t_local)\n",
    "    S_centralized = centralized_sq_mechanism(X_train, Y_train, eps, t_central)\n",
    "    avg_err_local += compute_statistics(S_local, X_test, Y_test)[0]\n",
    "    avg_err_centralized += compute_statistics(S_centralized, X_test, Y_test)[0]\n",
    "avg_err_local /= trials\n",
    "avg_err_centralized /= trials\n",
    "print(f\"The average error rate with the local model was {avg_err_local}\")\n",
    "print(f\"The average error rate with the centralized model was {avg_err_centralized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the centralized model learns almost perfectly, and the localized model learns fairly well - but has some number of false negatives (i.e. extra attributes are included and thus the model predicts positives too restrictively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's bootstrap smaller datasets to show the behavior of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704018f39e61461cb08f027adacd492d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trials = 10\n",
    "l_avg_fpr_local = []\n",
    "l_avg_fpr_centralized = []\n",
    "l_avg_fnr_local = []\n",
    "l_avg_fnr_centralized = []\n",
    "ns = np.linspace(1000, n_train, 20).astype(int)\n",
    "for n in tqdm_notebook(ns.tolist()):\n",
    "    indices = np.random.choice(np.arange(n_train), n, replace=False)\n",
    "    X = X_train[indices, :]\n",
    "    Y = Y_train[indices]\n",
    "    t_central = compute_centralized_t(n, d_train, eps)\n",
    "    t_local = compute_local_t(n, d_train, eps)\n",
    "    fpr_local = 0\n",
    "    fpr_centralized = 0\n",
    "    fnr_local = 0\n",
    "    fnr_centralized = 0\n",
    "    for _ in range(trials):\n",
    "        S_local = local_sq_mechanism(X, Y, eps, t_local)\n",
    "        S_centralized = centralized_sq_mechanism(X, Y, eps, t_central)\n",
    "        _, fpr, fnr = compute_statistics(S_local, X_test, Y_test)\n",
    "        fpr_local += fpr; fnr_local += fnr\n",
    "        _, fpr, fnr = compute_statistics(S_centralized, X_test, Y_test)\n",
    "        fpr_centralized += fpr; fnr_centralized += fnr\n",
    "    fpr_local /= trials\n",
    "    fnr_local /= trials\n",
    "    fpr_centralized /= trials\n",
    "    fnr_centralized /= trials\n",
    "    l_avg_fpr_local.append(fpr_local)\n",
    "    l_avg_fpr_centralized.append(fpr_centralized)\n",
    "    l_avg_fnr_local.append(fnr_local)\n",
    "    l_avg_fnr_centralized.append(fnr_centralized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_avg_fpr_local, l_avg_fpr_centralized, l_avg_fnr_local, l_avg_fnr_centralized = map(np.array, [l_avg_fpr_local, l_avg_fpr_centralized, l_avg_fnr_local, l_avg_fnr_centralized ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x122b7a2e8>"
      ]
     },
     "execution_count": 1239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ns, l_avg_fpr_local, label='local_fpr')\n",
    "plt.plot(ns, l_avg_fpr_centralized, label='centralized_fpr')\n",
    "plt.plot(ns, l_avg_fnr_local, label='local_fnr')\n",
    "plt.plot(ns, l_avg_fnr_centralized, label='centralized_fnr')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even at very small data quantities, the centralized model works almost perfectly. However, it takes much much more data for the local model to work well, and even after massive amounts of data it continues to have lots of false-negatives.\n",
    "\n",
    "(The fact that the initial FNR for the centralized model is so high might be a bug in calculating $t$ for extremely small, high-noise $n$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
