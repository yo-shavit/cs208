{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4b Submission\n",
    "## Yonadav Shavit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.special import factorial\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Let's define some latex commands)\n",
    " \n",
    "$\\newcommand{\\floor}[1]{\\left \\lfloor #1 \\right \\rfloor}$\n",
    "$\\newcommand{\\clamp}[1]{\\left [ #1 \\right ]}$\n",
    "$\\newcommand{\\lap}[1]{Lap\\left ( #1 \\right )}$\n",
    "$\\newcommand{\\lapcdf}[2]{LapCDF\\left ( #1, [-\\inf, #2] \\right )}$\n",
    "$\\newcommand{\\lappdf}[2]{LapPDF\\left ( #1, |_{#2} \\right )}$\n",
    "$\\newcommand{\\lapcdffull}[2]{\\frac{1}{2} + \\frac{1}{2}sgn\\left({#2}\\right)\\left ( 1 - \\exp{\\left ( - \\frac{|#2|}{#1} \\right ) }\\right )}$\n",
    "$\\newcommand{\\lappdffull}[2]{\\frac{1}{2 #1} \\exp{\\left ( - \\frac{#2}{#1}\\right ) }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "### (a)\n",
    "#### i.\n",
    "$GS_f = \\infty$ because the sensitivity is unbounded and so a single point can arbitrarily change the mean.\n",
    "#### ii.\n",
    "$\\min _{x \\in \\mathcal{S}} \\operatorname{LS}_{f}(x) = \\infty$ for the same reasons as above - regardless of any of the other points (i.e. $x$ s.t. we get minimum local sensitivity), a single additional point can arbitrarily change the resulting mean. (For example, to increase the mean by $k$, the new point should be $\\mu_{old} + nk$.)\n",
    "#### iii.\n",
    "$\\mathrm{RS}_{f}^{\\mathcal{H}} = \\frac{b-a}{n}$ because a single point can change only by $b-a$ while remaining in $H$, and so the average can only change by that divided by $n$.\n",
    "#### iv.\n",
    "We can construct an explicit Lipschitz extension by simply clipping each point to $[a, b]$ and then taking the mean and adding Laplace noise with sensitivity $\\frac{b-a}{n\\epsilon}$. This will be increasingly biased as the original data is farther from $[a, b]$, but the sensitivity will remain the same, and on $H$ this agrees with $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "#### i.\n",
    "$GS_f = \\infty$ because, for any large $N$, we can construct a dataset with $\\frac{n}{2}$ data points at $0$, and $\\frac{n}{2}$ datapoints at $N$, and then shifting a single point from $0$ to $N$ shifts the median by $N$, for any arbitrary $N$.\n",
    "#### ii.\n",
    "$\\min _{x \\in \\mathcal{S}} \\operatorname{LS}_{f}(x) = 0$ because if we create a dataset with $3$ points at $0$, no matter how much we change any single point, the other two will still be $0$ and so the median will be unchanged.\n",
    "#### iii.\n",
    "$\\mathrm{RS}_{f}^{\\mathcal{H}} = b-a$ because every point must fall in $[a, b]$, and so the largest possible change in median would be from $a$ to $b$. (This example is possible if half the points minus 1 are at $a$, and the other half are at $b$, and then we move one from $b$ to $a$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "#### i.\n",
    "$GS_f = n-1$ because if every node was previously disconnected (meaning the value was $n-1$) we can connect a new node to every old node, meaning that now $0$ nodes are disconnected.\n",
    "#### ii.\n",
    "$\\min _{x \\in \\mathcal{S}} \\operatorname{LS}_{f}(x) = 1$ because if every node in the graph is already connected, the addition of a new node cannot disconnect any existing nodes. The most it can do is add a node with no edges. (Note that our definition of node sensitivity in this case is a little weird, because if we're talking about deleting nodes rather than adding, the minimum local sensitivity is actually $0$, if all edges exist between all nodes.)\n",
    "#### iii.\n",
    "$\\mathrm{RS}_{f}^{\\mathcal{H}} = d$ because the greatest change from adding a single node would be that all existing nodes are unconnected, and then a single new node is added that connects to $d$ other nodes. \n",
    "(It can't connect to more than that because it must be in $H$). \n",
    "Thus the query can only decrease by $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lap_mechanism(epsilon, GS_q, size=None):\n",
    "    return np.random.laplace(scale=GS_q/epsilon, size=size)\n",
    "\n",
    "def dp_mean(x, epsilon, b, a=0):\n",
    "    x_clipped = np.clip(x, a, b)\n",
    "    GS_q = np.abs(b-a)/x.shape[0]\n",
    "    return x_clipped.mean() + lap_mechanism(epsilon, GS_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the R code, reproduced. I'm porting it into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Here is the likelihood function for a Logit\n",
    "calcllik<-function(b,data){           \n",
    "  y<-data[,1]\n",
    "  x<-data[,2]\n",
    "\n",
    "  pi<- 1/(1+exp(-b[1] - b[2]*x))        # Here is the systematic component\n",
    "\n",
    "  llik<-y * log(pi) + (1-y) * log(1-pi) # Here is the stocastic component\n",
    "  return(-llik)\n",
    "}\n",
    "\n",
    "## Differentially private mean release\n",
    "gaussianReleaseNoise <- function(size=1, sensitivity, epsilon, delta){\n",
    "\tscale <- sensitivity *log(1.25/delta)/ epsilon\n",
    "\tnoise <- rnorm(n=size, mean=0, sd=scale)\n",
    "\treturn(noise)\n",
    "}\n",
    "\n",
    "## Bound/Censor/Clip a variable to a range\n",
    "clip <- function(x, lower, upper){\n",
    "\tx.clipped <- x\n",
    "\tx.clipped[x.clipped<lower] <- lower\n",
    "\tx.clipped[x.clipped>upper] <- upper\n",
    "\treturn(x.clipped)\t\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Run with actual data\n",
    "\n",
    "library(\"foreign\")\n",
    "PUMSdata <- read.csv(file=\"../../data/MaPUMS5full.csv\")\n",
    "\n",
    "mydata<-PUMSdata[c(\"married\",\"educ\")]\n",
    "\n",
    "output <- glm(married ~ educ, family=\"binomial\", data=mydata)\n",
    "\n",
    "print(summary(output))\n",
    "\n",
    "\n",
    "#### Show the estimated model\n",
    "\n",
    "xseq <- seq(from=-40, to=60, length=100)\n",
    "f <- 1/(1 + exp(-output$coef[1] -output$coef[2]*xseq))\n",
    "\n",
    "par(mfcol=c(2,1))\n",
    "\n",
    "plot(xseq, f, type=\"l\", lwd=1.5, col=\"red\", ylim=c(0,1), ylab=\"E(y|x,theta)\", xlab=\"education\", main=\"Probability Married by Education\")\n",
    "abline(v=1, col=\"blue\", lty=3)\n",
    "abline(v=16, col=\"blue\", lty=3)\n",
    "\n",
    "plot(xseq, f, type=\"l\", lwd=1.5, col=\"red\", ylim=c(0,1), ylab=\"E(y|x,theta)\", xlab=\"education\", xlim=c(-5,20))\n",
    "for(i in 1:16){\n",
    "\tflag<-mydata$educ==i\n",
    "\tpoints(x=i, y=mean(mydata[flag,\"married\"]))\n",
    "}\n",
    "dev.copy2pdf(file=\"./figs/married_educ.pdf\")\n",
    "\n",
    "\n",
    "#### Show the LogLikelihood surface\n",
    "\n",
    "sample.data <- mydata[sample(1:nrow(mydata),10000), ]\n",
    "b1.seq <- seq(from=-3, to=2, length=25)\n",
    "b2.seq <- seq(from=-.2, to=.3, length=25)\n",
    "llsurface <- matrix(NA, nrow=length(b1.seq), ncol=length(b2.seq))\n",
    "\n",
    "for(i in 1:length(b1.seq)){\n",
    "\tfor(j in 1:length(b2.seq)){\n",
    "\t\tllsurface[i,j] <- sum(-1* calcllik(b=c(b1.seq[i], b2.seq[j]), data=sample.data) )\n",
    "\t}\n",
    "}\n",
    "\n",
    "filled.contour(x=b1.seq, y=b2.seq, z=llsurface, color = terrain.colors,  xlab=\"constant parameter\", ylab=\"education parameter\")\n",
    "\n",
    "dev.copy2pdf(file=\"./figs/logitLLike.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "calcgradient <- function(B, C, theta, fun){\n",
    "\tdx <- 0.0001\n",
    "\n",
    "\tout1 <-\teval(fun(b=theta, data=B))\n",
    "\tout2 <- eval(fun(b=theta + c(0,dx), data=B))\n",
    "\tout3 <- eval(fun(b=theta + c(dx,0), data=B))\n",
    "\n",
    "\tDel.1 <- 1\n",
    "\t# Del.1 <- clip(Del.1, lower=0, upper=1)  # Fix this\n",
    "\tmean.Del.1 <- mean(Del.1)\n",
    "\n",
    "\tDel.2 <- 1\n",
    "\t# Del.2 <- clip(Del.2, lower=0, upper=1)  # Fix this\n",
    "\tmean.Del.2 <- mean(Del.2)\n",
    "\n",
    "\treturn(c(mean.Del.1,mean.Del.2))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "N <- nrow(mydata)\n",
    "L <- round(sqrt(nrow(mydata)))\n",
    "\n",
    "steps <- 10   \t  # Fix this\n",
    "\n",
    "## Shuffle the data\n",
    "index <- sample(1:nrow(mydata))\n",
    "mydata <- mydata[index,]\n",
    "epsilon <-1\n",
    "\n",
    "theta <- c(0,0)   # Starting parameters\n",
    "C <- 10\t\t\t  # Interval to clip over\n",
    "nu <- c(1,0.01)   # Learning speeds\n",
    "\n",
    "\n",
    "history <- matrix(NA, nrow=steps+1, ncol=2)\n",
    "history[1,] <- theta\n",
    "\n",
    "for(i in 1:steps){\n",
    "\tstartB <- ((i-1)*L+1)\n",
    "\tif(i<L){\n",
    "\t\tstopB <- i*L\n",
    "\t}else{\n",
    "\t\tstopB <- nrow(mydata)\n",
    "\t}\n",
    "\n",
    "\tindex<-sample(1:nrow(mydata),L)\n",
    "\tB <- mydata[startB:stopB, ]\n",
    "\tDel <- calcgradient(B, C, theta, fun=calcllik)\n",
    "\tcat(\"Del:  \",Del,\"\\n\")\n",
    "\ttheta <- theta   \t\t\t\t# Fix this\n",
    "\tcat(\"Theta:\",theta, \"\\n\")\n",
    "\n",
    "\thistory[i+1,] <- theta\n",
    "\n",
    "}\n",
    "\n",
    "par(mfcol=c(2,1))\n",
    "\n",
    "all.ylim<-c( min(c(history[,1],output$coef[1] )), max(c(history[,1],output$coef[1] )))\n",
    "plot(history[,1], type=\"l\", ylim=all.ylim, ylab=\"beta 0\", xlab=\"step\", lwd=1.5)\n",
    "abline(h=output$coef[1], lty=2, col=\"blue\", lwd=1.5)\n",
    "\n",
    "\n",
    "all.ylim<-c( min(c(history[,2],output$coef[2] )), max(c(history[,2],output$coef[2] )))\n",
    "plot(history[,2], type=\"l\", ylim=all.ylim, ylab=\"beta 1\", xlab=\"step\", lwd=1.5)\n",
    "abline(h=output$coef[2], lty=2, col=\"blue\", lwd=1.5)\n",
    "\n",
    "dev.copy2pdf(file=\"./figs/dpSGD.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
